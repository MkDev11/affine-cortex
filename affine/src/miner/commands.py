"""
Miner Commands Implementation

Provides command functions for miners:
- commit_command: Commit model to blockchain
- pull_command: Pull model from Hugging Face
- chutes_push_command: Deploy model to Chutes
- deploy_command: One-command deployment (upload → deploy → commit)
"""

import os
import sys
import json
import asyncio
import textwrap
from pathlib import Path
from typing import Optional
from affine.utils.api_client import cli_api_client
from affine.core.setup import logger, NETUID
from affine.utils.subtensor import get_subtensor


def get_conf(key: str, default: Optional[str] = None) -> Optional[str]:
    """Get configuration value from environment variable."""
    return os.getenv(key, default)


# ============================================================================
# Private HuggingFace Repo Workflow Helpers
# ============================================================================

class PrivateRepoWorkflow:
    """Manages private HuggingFace repository workflow for secure model deployment.
    
    This workflow prevents other miners from monitoring and copying models before
    the original miner can commit to the blockchain. The flow is:
    
    1. Create PRIVATE HuggingFace repo
    2. Upload model to private HF repo
    3. Store HF_TOKEN as Chutes secret (so Chutes can access private repo)
    4. Deploy to Chutes (pulls from private HF repo using secret)
    5. Commit to blockchain
    6. Make HF repo PUBLIC after commit confirmed
    """
    
    CHUTES_API_BASE = "https://api.chutes.ai"
    SECRET_KEY_HF_TOKEN = "HF_TOKEN"
    
    def __init__(self, hf_token: str, chutes_api_key: str):
        """Initialize the workflow manager.
        
        Args:
            hf_token: HuggingFace API token with write access
            chutes_api_key: Chutes API key for secret management
        """
        self.hf_token = hf_token
        self.chutes_api_key = chutes_api_key
        self._hf_api = None
    
    @property
    def hf_api(self):
        """Lazy-load HuggingFace API client."""
        if self._hf_api is None:
            from huggingface_hub import HfApi
            self._hf_api = HfApi(token=self.hf_token)
        return self._hf_api
    
    def create_private_repo(self, repo_id: str) -> bool:
        """Create a private HuggingFace repository.
        
        Args:
            repo_id: Repository ID (e.g., "username/model-name")
            
        Returns:
            True if successful, False otherwise
        """
        try:
            self.hf_api.create_repo(
                repo_id=repo_id,
                exist_ok=True,
                repo_type="model",
                private=True
            )
            logger.info(f"Created/verified private repo: {repo_id}")
            return True
        except Exception as e:
            logger.error(f"Failed to create private repo {repo_id}: {e}")
            return False
    
    def upload_to_repo(
        self,
        repo_id: str,
        folder_path: str,
        commit_message: str = "Model update"
    ) -> Optional[str]:
        """Upload model folder to HuggingFace repository.
        
        Args:
            repo_id: Repository ID
            folder_path: Local path to model folder
            commit_message: Commit message for the upload
            
        Returns:
            Revision SHA if successful, None otherwise
        """
        try:
            self.hf_api.upload_folder(
                folder_path=folder_path,
                repo_id=repo_id,
                commit_message=commit_message
            )
            info = self.hf_api.repo_info(repo_id, repo_type="model")
            revision = info.sha
            logger.info(f"Uploaded to {repo_id}, revision: {revision[:12]}...")
            return revision
        except Exception as e:
            logger.error(f"Failed to upload to {repo_id}: {e}")
            return None
    
    def update_visibility(self, repo_id: str, private: bool) -> bool:
        """Update HuggingFace repository visibility.
        
        Args:
            repo_id: Repository ID
            private: True for private, False for public
            
        Returns:
            True if successful, False otherwise
        """
        try:
            from huggingface_hub import update_repo_settings
            update_repo_settings(
                repo_id=repo_id,
                private=private,
                token=self.hf_token
            )
            visibility = "private" if private else "public"
            logger.info(f"Updated {repo_id} visibility to {visibility}")
            return True
        except Exception as e:
            logger.error(f"Failed to update visibility for {repo_id}: {e}")
            return False
    
    def make_public(self, repo_id: str) -> bool:
        """Make a HuggingFace repository public.
        
        Args:
            repo_id: Repository ID
            
        Returns:
            True if successful, False otherwise
        """
        return self.update_visibility(repo_id, private=False)
    
    async def create_chutes_secret(
        self,
        chute_name: str,
        key: str,
        value: str
    ) -> bool:
        """Create a secret for a Chute deployment.
        
        This allows Chutes to access private HuggingFace repositories
        by storing the HF_TOKEN as an environment variable secret.
        
        Args:
            chute_name: Chute name or identifier for the secret purpose
            key: Secret key name (e.g., "HF_TOKEN")
            value: Secret value
            
        Returns:
            True if successful, False otherwise
        """
        import aiohttp
        
        url = f"{self.CHUTES_API_BASE}/secrets/"
        payload = {
            "purpose": chute_name,
            "key": key,
            "value": value
        }
        headers = {
            "Authorization": f"Bearer {self.chutes_api_key}",
            "Content-Type": "application/json"
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, headers=headers) as response:
                    if response.status in (200, 201):
                        data = await response.json()
                        secret_id = data.get("secret_id", data.get("id", "unknown"))
                        logger.info(f"Created Chutes secret '{key}' for {chute_name} (id: {secret_id})")
                        return True
                    else:
                        error_text = await response.text()
                        logger.error(f"Failed to create Chutes secret: {response.status} - {error_text}")
                        return False
        except Exception as e:
            logger.error(f"Failed to create Chutes secret: {e}")
            return False
    
    async def delete_chutes_secret(self, secret_id: str) -> bool:
        """Delete a Chutes secret by ID.
        
        Args:
            secret_id: Secret identifier to delete
            
        Returns:
            True if successful, False otherwise
        """
        import aiohttp
        
        url = f"{self.CHUTES_API_BASE}/secrets/{secret_id}"
        headers = {
            "Authorization": f"Bearer {self.chutes_api_key}"
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.delete(url, headers=headers) as response:
                    if response.status in (200, 204):
                        logger.info(f"Deleted Chutes secret: {secret_id}")
                        return True
                    else:
                        error_text = await response.text()
                        logger.warning(f"Failed to delete Chutes secret: {response.status} - {error_text}")
                        return False
        except Exception as e:
            logger.warning(f"Failed to delete Chutes secret: {e}")
            return False
    
    async def setup_private_repo_for_chutes(self, repo_id: str) -> bool:
        """Set up HF_TOKEN secret for Chutes to access private HF repo.
        
        Args:
            repo_id: Repository ID (used as purpose identifier)
            
        Returns:
            True if successful, False otherwise
        """
        return await self.create_chutes_secret(
            chute_name=repo_id,
            key=self.SECRET_KEY_HF_TOKEN,
            value=self.hf_token
        )
    
    async def execute_private_upload(
        self,
        repo_id: str,
        folder_path: str,
        commit_message: str = "Model update"
    ) -> Optional[str]:
        """Execute the private upload workflow.
        
        1. Create private HF repo
        2. Upload model
        3. Set up Chutes secret for private access
        
        Args:
            repo_id: Repository ID
            folder_path: Local path to model folder
            commit_message: Commit message
            
        Returns:
            Revision SHA if successful, None otherwise
        """
        if not self.create_private_repo(repo_id):
            return None
        
        revision = self.upload_to_repo(repo_id, folder_path, commit_message)
        if not revision:
            return None
        
        if not await self.setup_private_repo_for_chutes(repo_id):
            logger.warning("Failed to set up Chutes secret, deployment may fail")
        
        return revision
    
    async def finalize_after_commit(self, repo_id: str) -> bool:
        """Finalize workflow after successful on-chain commit.
        
        Makes the HuggingFace repository public so validators can access it.
        
        Args:
            repo_id: Repository ID
            
        Returns:
            True if successful, False otherwise
        """
        logger.info(f"Finalizing private repo workflow for {repo_id}...")
        success = self.make_public(repo_id)
        if success:
            logger.info(f"Repository {repo_id} is now public")
        else:
            logger.error(f"Failed to make {repo_id} public - manual intervention required")
        return success


# ============================================================================
# Command Implementations
# ============================================================================

async def pull_command(uid: int, model_path: str, hf_token: Optional[str] = None):
    """Pull model from Hugging Face.
    
    Args:
        uid: Miner UID
        model_path: Local directory to save model
        hf_token: Hugging Face API token (optional, from env if not provided)
    """
    from huggingface_hub import snapshot_download

    hf_token = hf_token or get_conf("HF_TOKEN")
    
    # Get miner info directly from subtensor
    try:
        subtensor = await get_subtensor()
        meta = await subtensor.metagraph(NETUID)
        commits = await subtensor.get_all_revealed_commitments(NETUID)
        
        if uid >= len(meta.hotkeys):
            logger.error(f"Invalid UID {uid}")
            print(json.dumps({"success": False, "error": f"Invalid UID {uid}"}))
            sys.exit(1)
        
        hotkey = meta.hotkeys[uid]
        
        if hotkey not in commits:
            logger.error(f"No commit found for UID {uid}")
            print(json.dumps({"success": False, "error": f"No commit found for UID {uid}"}))
            sys.exit(1)
        
        _, commit_data = commits[hotkey][-1]
        data = json.loads(commit_data)
        
        repo_name = data.get("model")
        revision = data.get("revision")
        
        if not repo_name:
            logger.error(f"Miner {uid} has no model configured")
            print(json.dumps({"success": False, "error": "No model configured"}))
            sys.exit(1)
    except Exception as e:
        logger.error(f"Failed to get miner info: {e}")
        print(json.dumps({"success": False, "error": str(e)}))
        sys.exit(1)
    
    logger.info(f"Pulling model {repo_name}@{revision} for UID {uid} into {model_path}")
    
    try:
        snapshot_download(
            repo_id=repo_name,
            repo_type="model",
            local_dir=model_path,
            token=hf_token,
            resume_download=True,
            revision=revision,
        )
        
        result = {
            "success": True,
            "uid": uid,
            "repo": repo_name,
            "revision": revision,
            "path": model_path
        }
        print(json.dumps(result))
        logger.info(f"Model {repo_name} pulled successfully")
    
    except Exception as e:
        logger.error(f"Failed to download {repo_name}: {e}")
        print(json.dumps({"success": False, "error": str(e)}))
        sys.exit(1)


async def get_latest_chute_id(repo: str, api_key: str) -> Optional[str]:
    """Get latest chute ID for a repository.
    
    Args:
        repo: HF repository name
        api_key: Chutes API key
    
    Returns:
        Chute ID or None if not found
    """
    token = api_key or os.getenv("CHUTES_API_KEY", "")
    if not token:
        return None
    
    try:
        import aiohttp
        async with aiohttp.ClientSession() as session:
            async with session.get(
                "https://api.chutes.ai/chutes/", headers={"Authorization": token}
            ) as r:
                if r.status != 200:
                    return None
                data = await r.json()
    except Exception:
        return None
    
    chutes = data.get("items", data) if isinstance(data, dict) else data
    if not isinstance(chutes, list):
        return None
    
    for chute in reversed(chutes):
        if any(chute.get(k) == repo for k in ("model_name", "name", "readme")):
            return chute.get("chute_id")
    return None


async def chutes_push_command(
    repo: str,
    revision: str,
    chutes_api_key: Optional[str] = None,
    chute_user: Optional[str] = None
):
    """Deploy model to Chutes.
    
    Args:
        repo: HF repository ID
        revision: HF commit SHA
        chutes_api_key: Chutes API key (optional, from env if not provided)
        chute_user: Chutes username (optional, from env if not provided)
    """
    chutes_api_key = chutes_api_key or get_conf("CHUTES_API_KEY")
    chute_user = chute_user or get_conf("CHUTE_USER")
    
    if not chutes_api_key:
        logger.error("CHUTES_API_KEY not configured")
        print(json.dumps({"success": False, "error": "CHUTES_API_KEY not configured"}))
        sys.exit(1)
    
    if not chute_user:
        logger.error("CHUTE_USER not configured")
        print(json.dumps({"success": False, "error": "CHUTE_USER not configured"}))
        sys.exit(1)
    
    logger.debug(f"Building Chute config for repo={repo} revision={revision}")
    
    # Generate Chute configuration
    chutes_config = textwrap.dedent(
        f"""
import os
from chutes.chute import NodeSelector
from chutes.chute.template.sglang import build_sglang_chute
os.environ["NO_PROXY"] = "localhost,127.0.0.1"

chute = build_sglang_chute(
    username="{chute_user}",
    readme="{repo}",
    model_name="{repo}",
    image="chutes/sglang:nightly-2025081600",
    concurrency=40,
    revision="{revision}",
    node_selector=NodeSelector(
        gpu_count=4,
        include=["h200"],
    ),
    scaling_threshold=0.5,
    max_instances=2,
    shutdown_after_seconds=28800,
)
"""
    )
    
    tmp_file = Path("tmp_chute.py")
    tmp_file.write_text(chutes_config)
    logger.debug(f"Wrote Chute config to {tmp_file}")
    
    # Deploy to Chutes
    cmd = ["chutes", "deploy", f"{tmp_file.stem}:chute", "--accept-fee"]
    env = {**os.environ, "CHUTES_API_KEY": chutes_api_key}
    
    try:
        proc = await asyncio.create_subprocess_exec(
            *cmd,
            env=env,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.STDOUT,
            stdin=asyncio.subprocess.PIPE,
        )
        
        if proc.stdin:
            proc.stdin.write(b"y\n")
            await proc.stdin.drain()
            proc.stdin.close()
        
        stdout, _ = await proc.communicate()
        output = stdout.decode(errors="ignore")
        logger.trace(output)
        
        # Check for errors
        import re
        match = re.search(
            r"(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+\|\s+(\w+)", output
        )
        if match and match.group(2) == "ERROR":
            logger.debug("Chutes deploy failed with error log")
            raise RuntimeError("Chutes deploy failed")
        
        if proc.returncode != 0:
            logger.debug(f"Chutes deploy failed with code {proc.returncode}")
            raise RuntimeError("Chutes deploy failed")
        
        tmp_file.unlink(missing_ok=True)
        logger.debug("Chute deployment successful")
        
        # Get chute info
        from affine.utils.api_client import get_chute_info
        chute_id = await get_latest_chute_id(repo, api_key=chutes_api_key)
        chute_info = await get_chute_info(chute_id) if chute_id else None
        
        result = {
            "success": bool(chute_id),
            "chute_id": chute_id,
            "chute": chute_info,
            "repo": repo,
            "revision": revision,
        }
        print(json.dumps(result))
        logger.info(f"Deployed to Chutes: {chute_id}")
    
    except Exception as e:
        logger.error(f"Chutes deployment failed: {e}")
        print(json.dumps({"success": False, "error": str(e)}))
        tmp_file.unlink(missing_ok=True)
        sys.exit(1)


async def commit_command(
    repo: str,
    revision: str,
    chute_id: str,
    coldkey: Optional[str] = None,
    hotkey: Optional[str] = None
):
    """Commit model to blockchain.

    Args:
        repo: HF repository ID
        revision: HF commit SHA
        chute_id: Chutes deployment ID
        coldkey: Wallet coldkey name (optional, from env if not provided)
        hotkey: Wallet hotkey name (optional, from env if not provided)
    """
    import bittensor as bt
    from bittensor.core.errors import MetadataError
    from affine.utils.subtensor import get_subtensor

    cold = coldkey or get_conf("BT_WALLET_COLD", "default")
    hot = hotkey or get_conf("BT_WALLET_HOT", "default")
    wallet = bt.Wallet(name=cold, hotkey=hot)
    
    logger.info(f"Committing: {repo}@{revision} (chute: {chute_id})")
    logger.info(f"Using wallet: {wallet.hotkey.ss58_address[:16]}...")

    async def _commit():
        sub = await get_subtensor()
        data = json.dumps({
            "model": repo,
            "revision": revision,
            "chute_id": chute_id
        })
        
        while True:
            try:
                await sub.set_reveal_commitment(
                    wallet=wallet,
                    netuid=NETUID,
                    data=data,
                    blocks_until_reveal=1
                )
                break
            except MetadataError as e:
                if "SpaceLimitExceeded" in str(e):
                    logger.warning("Space limit exceeded, waiting for next block...")
                    await sub.wait_for_block()
                else:
                    raise
    
    try:
        await _commit()
        
        result = {
            "success": True,
            "repo": repo,
            "revision": revision,
            "chute_id": chute_id,
        }
        print(json.dumps(result))
        logger.info("Commit successful")
    
    except Exception as e:
        logger.error(f"Commit failed: {e}")
        print(json.dumps({"success": False, "error": str(e)}))
        sys.exit(1)


async def get_sample_command(
    uid: int,
    env: str,
    task_id: str,
):
    """Query sample result by UID, environment, and task ID.
    
    Args:
        uid: Miner UID
        env: Environment name
        task_id: Task ID
    """
    
    async with cli_api_client() as client:
        endpoint = f"/samples/uid/{uid}/{env}/{task_id}"
        data = await client.get(endpoint)
        
        if data:
            print(json.dumps(data, indent=2, ensure_ascii=False))


async def get_miner_command(uid: int):
    """Query miner status and information by UID.
    
    Args:
        uid: Miner UID
    """
    async with cli_api_client() as client:
        endpoint = f"/miners/uid/{uid}"
        data = await client.get(endpoint)
        if data:
            print(json.dumps(data, indent=2, ensure_ascii=False))
            
            # Fetch and display sampling stats via API
            stats_endpoint = f"/miners/uid/{uid}/stats"
            stats_data = await client.get(stats_endpoint)
            
            if stats_data and stats_data.get('sampling_stats'):
                print("\n" + "="*80)
                print("GLOBAL SAMPLING STATISTICS")
                print("="*80)
                
                sampling_stats = stats_data['sampling_stats']
                
                for window in ['last_15min', 'last_1hour', 'last_6hours', 'last_24hours']:
                    if window in sampling_stats:
                        wstats = sampling_stats[window]
                        print(f"\n{window}:")
                        print(f"  Samples: {wstats.get('samples', 0)}")
                        print(f"  Success: {wstats.get('success', 0)}")
                        print(f"  Success rate: {wstats.get('success_rate', 0.0):.2%}")
                        print(f"  Samples/min: {wstats.get('samples_per_min', 0.0):.2f}")
                        print(f"  Rate limit errors: {wstats.get('rate_limit_errors', 0)}")
                        print(f"  Timeout errors: {wstats.get('timeout_errors', 0)}")
                        print(f"  Other errors: {wstats.get('other_errors', 0)}")
                
                # Display per-environment statistics
                if stats_data.get('env_stats'):
                    print("\n" + "="*80)
                    print("PER-ENVIRONMENT STATISTICS")
                    print("="*80)
                    
                    env_stats = stats_data['env_stats']
                    for env_name, env_data in env_stats.items():
                        print(f"\n[{env_name}]")
                        for window in ['last_15min', 'last_1hour', 'last_6hours', 'last_24hours']:
                            if window in env_data:
                                wstats = env_data[window]
                                print(f"  {window}:")
                                print(f"    Samples: {wstats.get('samples', 0)}")
                                print(f"    Success: {wstats.get('success', 0)}")
                                print(f"    Success rate: {wstats.get('success_rate', 0.0):.2%}")
                                print(f"    Samples/min: {wstats.get('samples_per_min', 0.0):.2f}")
                                print(f"    Rate limit errors: {wstats.get('rate_limit_errors', 0)}")
                                print(f"    Timeout errors: {wstats.get('timeout_errors', 0)}")
                                print(f"    Other errors: {wstats.get('other_errors', 0)}")
            else:
                print("\n" + "="*80)
                print("No sampling statistics available for this miner.")
                print("="*80)



async def get_weights_command():
    """Query latest normalized weights for on-chain weight setting.
    
    Returns the most recent score snapshot with normalized weights
    for all miners.
    """
    async with cli_api_client() as client:
        endpoint = "/scores/weights/latest"
        data = await client.get(endpoint)
        
        if data:
            print(json.dumps(data, indent=2, ensure_ascii=False))


async def get_scores_command(top: int = 32):
    """Query latest scores for top N miners.
    
    Args:
        top: Number of top miners to return (default: 256)
    """
    async with cli_api_client() as client:
        endpoint = f"/scores/latest?top={top}"
        data = await client.get(endpoint)
        
        if data:
            print(json.dumps(data, indent=2, ensure_ascii=False))


async def get_score_command(uid: int):
    """Query score for a specific miner by UID.
    
    Args:
        uid: Miner UID
    """
    async with cli_api_client() as client:
        endpoint = f"/scores/uid/{uid}"
        data = await client.get(endpoint)
        
        if data:
            print(json.dumps(data, indent=2, ensure_ascii=False))


async def get_pool_command(uid: int, env: str, full: bool = False):
    """Query task pool status for a miner in an environment.
    
    Args:
        uid: Miner UID
        env: Environment name (e.g., agentgym:webshop)
        full: If True, print full task_ids lists without truncation
    """
    async with cli_api_client() as client:
        endpoint = f"/samples/pool/uid/{uid}/{env}"
        data = await client.get(endpoint)
        
        if data:
            if data.get("success") is False:
                print(json.dumps({
                    "error": data.get("error"),
                    "status_code": data.get("status_code")
                }, indent=2, ensure_ascii=False))
                return
            if full:
                # Print full data without truncation
                print(json.dumps(data, indent=2, ensure_ascii=False))
            else:
                # Format output for better readability
                # Show summary first, then task_ids ranges instead of full lists
                summary = {
                    "uid": data.get("uid"),
                    "hotkey": data.get("hotkey"),
                    "model_revision": data.get("model_revision"),
                    "env": data.get("env"),
                    "sampling_config": data.get("sampling_config", {}),
                    "total_tasks": data.get("total_tasks"),
                    "sampled_count": data.get("sampled_count"),
                    "pool_count": data.get("pool_count"),
                    "missing_count": data.get("missing_count"),
                }
                
                # Helper function to format task_id list as ranges
                def format_task_ids(task_ids):
                    if not task_ids:
                        return "[]"
                    if len(task_ids) <= 10:
                        return str(task_ids)
                    # Show first 5 and last 5
                    return f"[{', '.join(map(str, task_ids[:5]))}, ..., {', '.join(map(str, task_ids[-5:]))}] (total: {len(task_ids)})"
                
                summary["sampled_task_ids"] = format_task_ids(data.get("sampled_task_ids", []))
                summary["pool_task_ids"] = format_task_ids(data.get("pool_task_ids", []))
                summary["missing_task_ids"] = format_task_ids(data.get("missing_task_ids", []))
                
                print(json.dumps(summary, indent=2, ensure_ascii=False))


async def get_envs_command():
    """Query current environment configurations.
    
    Returns all environment configurations including sampling settings,
    rotation settings, and enabled flags.
    """
    async with cli_api_client() as client:
        endpoint = "/config/environments"
        data = await client.get(endpoint)
        
        if data:
            print(json.dumps(data, indent=2, ensure_ascii=False))


async def deploy_command(
    repo: str,
    model_path: Optional[str] = None,
    revision: Optional[str] = None,
    chute_id: Optional[str] = None,
    message: str = "Model update",
    dry_run: bool = False,
    skip_upload: bool = False,
    skip_chutes: bool = False,
    skip_commit: bool = False,
    chutes_api_key: Optional[str] = None,
    chute_user: Optional[str] = None,
    coldkey: Optional[str] = None,
    hotkey: Optional[str] = None,
    hf_token: Optional[str] = None,
    private_repo: bool = False,
):
    """One-command deployment: Upload to HuggingFace -> Deploy to Chutes -> Commit on-chain.
    
    This combines the three-step deployment process into a single command:
    1. Upload model to HuggingFace (skip with --skip-upload if already uploaded)
    2. Deploy to Chutes (skip with --skip-chutes if already deployed)
    3. Commit on-chain (skip with --skip-commit to test without committing)
    4. Make HF repo public (if --private-repo was used)
    
    Private Repo Workflow (--private-repo):
    Prevents other miners from monitoring and copying your model before commit.
    The workflow creates a private HF repo, stores HF_TOKEN as a Chutes secret,
    deploys, commits, then makes the repo public.
    
    Args:
        repo: HuggingFace repository ID (e.g., "username/model-name")
        model_path: Path to local model directory (required unless --skip-upload)
        revision: HuggingFace revision SHA (required if --skip-upload)
        chute_id: Chutes deployment ID (required if --skip-chutes)
        message: Commit message for HuggingFace upload
        dry_run: If True, show what would be done without executing
        skip_upload: Skip HuggingFace upload (requires --revision)
        skip_chutes: Skip Chutes deployment (requires --chute-id)
        skip_commit: Skip on-chain commit
        chutes_api_key: Chutes API key (optional, from env if not provided)
        chute_user: Chutes username (optional, from env if not provided)
        coldkey: Wallet coldkey name (optional, from env if not provided)
        hotkey: Wallet hotkey name (optional, from env if not provided)
        hf_token: HuggingFace token (optional, from env if not provided)
        private_repo: Use private HF repo workflow (publish after commit)
    """
    from huggingface_hub import HfApi
    
    chutes_api_key = chutes_api_key or get_conf("CHUTES_API_KEY")
    chute_user = chute_user or get_conf("CHUTE_USER")
    hf_token = hf_token or get_conf("HF_TOKEN")
    
    # Validate arguments based on skip flags
    if not skip_upload and not model_path:
        logger.error("--model-path is required unless --skip-upload is set")
        print(json.dumps({"success": False, "error": "--model-path is required unless --skip-upload is set"}))
        sys.exit(1)
    
    if skip_upload and not revision:
        logger.error("--revision is required when --skip-upload is set")
        print(json.dumps({"success": False, "error": "--revision is required when --skip-upload is set"}))
        sys.exit(1)
    
    if skip_chutes and not chute_id:
        logger.error("--chute-id is required when --skip-chutes is set")
        print(json.dumps({"success": False, "error": "--chute-id is required when --skip-chutes is set"}))
        sys.exit(1)
    
    # Validate required credentials
    if not dry_run:
        if not skip_upload and not hf_token:
            logger.error("HF_TOKEN not configured")
            print(json.dumps({"success": False, "error": "HF_TOKEN not configured"}))
            sys.exit(1)
        
        if not skip_chutes:
            if not chutes_api_key:
                logger.error("CHUTES_API_KEY not configured")
                print(json.dumps({"success": False, "error": "CHUTES_API_KEY not configured"}))
                sys.exit(1)
            
            if not chute_user:
                logger.error("CHUTE_USER not configured")
                print(json.dumps({"success": False, "error": "CHUTE_USER not configured"}))
                sys.exit(1)
    
    # Determine which steps to run
    steps = []
    if not skip_upload:
        steps.append("upload")
    if not skip_chutes:
        steps.append("chutes")
    if not skip_commit:
        steps.append("commit")
    
    total_steps = len(steps)
    current_step = 0
    
    logger.info("=" * 60)
    logger.info("AFFINE DEPLOYMENT")
    logger.info("=" * 60)
    logger.info(f"  Repository: {repo}")
    if model_path:
        logger.info(f"  Model Path: {model_path}")
    if revision:
        logger.info(f"  Revision: {revision}")
    if chute_id:
        logger.info(f"  Chute ID: {chute_id}")
    logger.info(f"  Steps: {' -> '.join(steps) if steps else 'none'}")
    if private_repo:
        logger.info("  Mode: PRIVATE REPO (will publish after commit)")
    if dry_run:
        logger.info("  Mode: DRY RUN")
    logger.info("=" * 60)
    
    # Initialize private repo workflow manager if needed
    private_workflow = None
    if private_repo and not dry_run:
        private_workflow = PrivateRepoWorkflow(
            hf_token=hf_token,
            chutes_api_key=chutes_api_key
        )
    
    # =========================================================================
    # Step 1: Upload to HuggingFace
    # =========================================================================
    if not skip_upload:
        current_step += 1
        upload_mode = "PRIVATE" if private_repo else "public"
        logger.info(f"[{current_step}/{total_steps}] Uploading to HuggingFace ({repo}) [{upload_mode}]...")
        
        if dry_run:
            logger.info(f"  [DRY RUN] Would upload {model_path} to {repo} (private={private_repo})")
            revision = "dry-run-revision-sha"
        else:
            try:
                # Use private workflow if enabled
                if private_workflow:
                    logger.info(f"  Using private repo workflow...")
                    revision = await private_workflow.execute_private_upload(
                        repo_id=repo,
                        folder_path=model_path,
                        commit_message=message
                    )
                    if not revision:
                        raise RuntimeError("Private upload workflow failed")
                    logger.info(f"  Private upload complete. Revision: {revision[:12]}...")
                else:
                    # Standard public upload
                    api = HfApi(token=hf_token)
                    
                    # Create repo if doesn't exist
                    try:
                        api.create_repo(repo, exist_ok=True, repo_type="model")
                        logger.debug(f"Repository {repo} ready")
                    except Exception as e:
                        logger.debug(f"Repo creation note: {e}")
                    
                    # Upload folder
                    logger.info(f"  Uploading {model_path}...")
                    api.upload_folder(
                        folder_path=model_path,
                        repo_id=repo,
                        commit_message=message
                    )
                    
                    # Get latest commit SHA
                    info = api.repo_info(repo, repo_type="model")
                    revision = info.sha
                    
                    logger.info(f"  Upload complete. Revision: {revision[:12]}...")
                
            except Exception as e:
                logger.error(f"HuggingFace upload failed: {e}")
                print(json.dumps({"success": False, "error": f"HuggingFace upload failed: {str(e)}"}))
                sys.exit(1)
    else:
        logger.info(f"Skipping upload, using revision: {revision[:12]}...")
    
    # =========================================================================
    # Step 2: Deploy to Chutes
    # =========================================================================
    if not skip_chutes:
        current_step += 1
        logger.info(f"[{current_step}/{total_steps}] Deploying to Chutes...")
        
        if dry_run:
            logger.info(f"  [DRY RUN] Would deploy {repo}@{revision[:12]}...")
            chute_id = "dry-run-chute-id"
        else:
            try:
                # Generate Chute configuration (same as chutes_push_command)
                chutes_config = textwrap.dedent(
                    f"""
import os
from chutes.chute import NodeSelector
from chutes.chute.template.sglang import build_sglang_chute
os.environ["NO_PROXY"] = "localhost,127.0.0.1"

chute = build_sglang_chute(
    username="{chute_user}",
    readme="{repo}",
    model_name="{repo}",
    image="chutes/sglang:nightly-2025081600",
    concurrency=40,
    revision="{revision}",
    node_selector=NodeSelector(
        gpu_count=4,
        include=["h200"],
    ),
    scaling_threshold=0.5,
    max_instances=2,
    shutdown_after_seconds=28800,
)
"""
                )
                
                tmp_file = Path("tmp_chute.py")
                tmp_file.write_text(chutes_config)
                logger.debug(f"Wrote Chute config to {tmp_file}")
                
                # Deploy to Chutes
                cmd = ["chutes", "deploy", f"{tmp_file.stem}:chute", "--accept-fee"]
                env = {**os.environ, "CHUTES_API_KEY": chutes_api_key}
                
                proc = await asyncio.create_subprocess_exec(
                    *cmd,
                    env=env,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.STDOUT,
                    stdin=asyncio.subprocess.PIPE,
                )
                
                if proc.stdin:
                    proc.stdin.write(b"y\n")
                    await proc.stdin.drain()
                    proc.stdin.close()
                
                stdout, _ = await proc.communicate()
                output = stdout.decode(errors="ignore")
                logger.trace(output)
                
                # Check for errors
                import re
                match = re.search(
                    r"(\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+\|\s+(\w+)", output
                )
                if match and match.group(2) == "ERROR":
                    logger.debug("Chutes deploy failed with error log")
                    raise RuntimeError("Chutes deploy failed")
                
                if proc.returncode != 0:
                    logger.debug(f"Chutes deploy failed with code {proc.returncode}")
                    raise RuntimeError("Chutes deploy failed")
                
                tmp_file.unlink(missing_ok=True)
                logger.debug("Chute deployment successful")
                
                # Get chute ID
                chute_id = await get_latest_chute_id(repo, api_key=chutes_api_key)
                
                if not chute_id:
                    raise RuntimeError("Failed to get chute_id after deployment")
                
                logger.info(f"  Chutes deployment complete. Chute ID: {chute_id}")
                
            except Exception as e:
                logger.error(f"Chutes deployment failed: {e}")
                if 'tmp_file' in locals():
                    tmp_file.unlink(missing_ok=True)
                print(json.dumps({"success": False, "error": f"Chutes deployment failed: {str(e)}"}))
                sys.exit(1)
    else:
        logger.info(f"Skipping Chutes deployment, using chute_id: {chute_id}")
    
    # =========================================================================
    # Step 3: Commit on-chain
    # =========================================================================
    if not skip_commit:
        current_step += 1
        logger.info(f"[{current_step}/{total_steps}] Committing on-chain...")
        
        if dry_run:
            logger.info(f"  [DRY RUN] Would commit {repo}@{revision[:12]}... with chute {chute_id}")
        else:
            try:
                import bittensor as bt
                from bittensor.core.errors import MetadataError
                from affine.utils.subtensor import get_subtensor
                
                cold = coldkey or get_conf("BT_WALLET_COLD", "default")
                hot = hotkey or get_conf("BT_WALLET_HOT", "default")
                wallet = bt.Wallet(name=cold, hotkey=hot)
                
                logger.info(f"  Using wallet: {wallet.hotkey.ss58_address[:16]}...")
                
                sub = await get_subtensor()
                data = json.dumps({
                    "model": repo,
                    "revision": revision,
                    "chute_id": chute_id
                })
                
                while True:
                    try:
                        await sub.set_reveal_commitment(
                            wallet=wallet,
                            netuid=NETUID,
                            data=data,
                            blocks_until_reveal=1
                        )
                        break
                    except MetadataError as e:
                        if "SpaceLimitExceeded" in str(e):
                            logger.warning("Space limit exceeded, waiting for next block...")
                            await sub.wait_for_block()
                        else:
                            raise
                
                logger.info("  Commit successful")
                
                # =========================================================
                # Step 4: Make HF repo public (if private workflow)
                # =========================================================
                if private_workflow:
                    logger.info(f"[{current_step}/{total_steps}] Making HF repo public...")
                    if not await private_workflow.finalize_after_commit(repo):
                        logger.warning("Failed to make repo public - manual intervention may be required")
                        logger.warning(f"Run: huggingface-cli repo visibility {repo} --public")
                
            except Exception as e:
                logger.error(f"On-chain commit failed: {e}")
                print(json.dumps({"success": False, "error": f"On-chain commit failed: {str(e)}"}))
                sys.exit(1)
    else:
        logger.info("Skipping on-chain commit")
        
        # If skipping commit but using private repo, warn user
        if private_repo:
            logger.warning("Private repo workflow: HF repo remains PRIVATE since commit was skipped")
            logger.warning(f"To make public later: huggingface-cli repo visibility {repo} --public")
    
    # =========================================================================
    # Summary
    # =========================================================================
    logger.info("=" * 60)
    if dry_run:
        logger.info("DRY RUN COMPLETE - No changes were made")
    else:
        logger.info("DEPLOYMENT COMPLETE")
    logger.info("=" * 60)
    logger.info(f"  Repository: {repo}")
    logger.info(f"  Revision: {revision[:12] if revision and len(revision) > 12 else revision}...")
    logger.info(f"  Chute ID: {chute_id}")
    logger.info("=" * 60)
    
    result = {
        "success": True,
        "repo": repo,
        "revision": revision,
        "chute_id": chute_id,
        "dry_run": dry_run,
        "private_repo": private_repo,
        "repo_visibility": "public" if (private_repo and not skip_commit and not dry_run) else ("private" if private_repo else "public")
    }
    print(json.dumps(result))